# ДЗ: MLflow

Пайплайн: данные → обучение → оценка. Всё логируется в MLflow.

## Как запустить

```bash
pip install -r requirements.txt
```

Один эксперимент (параметры в `params/*.yaml`):

```bash
python runner.py
```

Серия из 14 экспериментов:

```bash
python run_experiments.py
```

MLflow: http://158.160.2.37:5000/ , эксперимент задаётся в `constants.py` (`EXPERIMENT_NAME`).

Лучшие параметры по ROC-AUC лежат в `params/best_params.yaml` — можно скопировать в соответствующие yaml и запустить `python runner.py`.

---

## Отчёт по экспериментам

Проведено 14 экспериментов в четырёх разрезах (в каждом менялся один параметр).

### 1. Размер тренировочного датасета

**Гипотеза:** больше данных — лучше качество.

**Параметр:** `data_train_size`. Значения: 2000, 5000, 10000, 15000. Модель: Logistic Regression, фичи: base.

| train_size | accuracy | precision | recall | f1_score | roc_auc | pr_auc |
|------------|----------|-----------|--------|----------|---------|--------|
| 2000       | 0.791    | 0.664     | 0.254  | 0.368    | 0.801   | 0.594   |
| 5000       | 0.791    | 0.664     | 0.262  | 0.375    | 0.802   | 0.595   |
| 10000      | 0.792    | 0.666     | 0.267  | 0.381    | 0.802   | 0.594   |
| 15000      | 0.792    | 0.660     | 0.268  | 0.382    | 0.802   | 0.594   |

**Вывод:** небольшой рост качества с 2000 до 5–10k, дальше стабилизация. Для LR на этих фичах выигрыш от ещё больших данных маленький.

### 2. Тип модели

**Гипотеза:** ансамбли (RF, GB) лучше по ROC-AUC, чем простая LR и дерево.

**Параметр:** `model_type`. train_size=10000, фичи: base.

| model_type          | roc_auc | accuracy | f1_score |
|---------------------|---------|----------|----------|
| logistic_regression | 0.802   | 0.792    | 0.381    |
| decision_tree       | 0.837   | 0.823    | 0.581    |
| random_forest       | 0.872   | 0.838    | 0.580    |
| gradient_boosting   | 0.884   | 0.846    | 0.625    |

**Вывод:** гипотеза подтверждается. Лучший результат у Gradient Boosting (roc_auc 0.884).

### 3. Гиперпараметры Logistic Regression

**Гипотеза:** C и solver влияют на качество.

**Параметры:** (C, solver) = (0.1, lbfgs), (1.0, lbfgs), (10.0, saga). train_size=10000, фичи: base.

| C    | solver | roc_auc |
|------|--------|---------|
| 0.1  | lbfgs  | 0.802   |
| 1.0  | lbfgs  | 0.802   |
| 10.0 | saga   | 0.411   |

Для C=10 и saga за 1000 итераций модель не сошлась — качество упало.

**Вывод:** для lbfgs смена C в 0.1–1.0 почти не меняет roc_auc. saga при том же max_iter дал плохой результат.

### 4. Набор признаков

**Гипотеза:** больше признаков — лучше предсказание.

**Параметр:** `data_features_set` (minimal / base / extended). train_size=10000, модель: LR.

| features_set | roc_auc |
|-------------|---------|
| minimal     | 0.774   |
| base        | 0.802   |
| extended    | 0.816   |

**Вывод:** гипотеза подтверждается. Extended дал лучший roc_auc среди вариантов с LR.

### Лучший запуск по ROC-AUC

Gradient Boosting, roc_auc ≈ 0.884. Параметры в `params/best_params.yaml`.

Ссылка на run в MLflow: http://158.160.2.37:5000/#/experiments/31/runs/8a21d0fb985b4c41b998f8f531f99260  
(эксперимент может быть другой — смотрите свой `EXPERIMENT_NAME` в UI и сортируйте по roc_auc по убыванию)
